{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "chicken.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9Zq8jkOQ+vhfEgj6JPk7e",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashimdahal/Chicken-Recipe-Generator/blob/main/chicken.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f86w1k5pBo2P"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib.request"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOIjy9KHB_jk",
        "outputId": "cd95c5ef-bf21-46b4-a9da-8604c7031fda"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjJeF_LMsr_o",
        "outputId": "f63d4aa0-ce9a-4f5f-e472-82350a46f759"
      },
      "source": [
        "!ls '/content/gdrive'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilMx1GwCCV7B"
      },
      "source": [
        "text = open('/content/gdrive/MyDrive/chicken.txt').read()\n",
        "dataset_orig = text.split('\\n')\n",
        "dataset_orig = [i.lower().replace('.','').replace(',','') for i in dataset_orig]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_FSBdBwEFWS",
        "outputId": "91d894de-eaad-410a-ba7c-c4adf1e57f92"
      },
      "source": [
        "np.array(dataset_orig).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRs0H_HdEYg6"
      },
      "source": [
        "url = 'http://vectors.nlpl.eu/repository/20/18.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJPXdU20HiUI"
      },
      "source": [
        "\n",
        "with urllib.request.urlopen(url) as f:\n",
        "    open('text.zip',mode='wb').write(f.read())\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMYi8Nw0HsLC"
      },
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/text.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"targetdir\")\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBzJwSTHKJbV"
      },
      "source": [
        "import io\n",
        "\n",
        "def load_vectors(fname):\n",
        "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    n, d = map(int, fin.readline().split())\n",
        "    data = {}\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        data[tokens[0]] = list(map(float, tokens[1:]))\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8DDt9cBMFVh"
      },
      "source": [
        "embedding = load_vectors('/content/targetdir/model.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfpI-eq4XyZs"
      },
      "source": [
        "def sen_to_list(sentence):\n",
        "    return sentence.split(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L9C8wCb9vh-"
      },
      "source": [
        "largest_recipe = len(max(dataset_orig,key=len))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwuaGrkIgYt4"
      },
      "source": [
        "embedding['serves'] = embedding['serve']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSKme2PnZlJ4"
      },
      "source": [
        "def get_embedding_for_words(word,embedding):\n",
        "    sentence_in_vec = []\n",
        "    \n",
        "    if word in embedding.keys():\n",
        "        sentence_in_vec.append(np.array(embedding[word]))\n",
        "    else:\n",
        "        sentence_in_vec.append(np.zeros(300))\n",
        "    \n",
        "    return np.array(sentence_in_vec)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrUpSRF3tMI2"
      },
      "source": [
        "char_to_idx ={}\n",
        "for id,key in enumerate(embedding.keys()):\n",
        "    char_to_idx[key] = id \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSzcNFvyyBs7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f574f5f-4cb8-4888-e030-cceb1f9c8f99"
      },
      "source": [
        "char_to_idx['chicken']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5240"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJsNXUCEhpCj"
      },
      "source": [
        "def word_to_id(word):\n",
        "    out =[]\n",
        "    if type(word) == type([]):\n",
        "        word = np.array(word).reshape(-1)\n",
        "        for w in word:\n",
        "            if w in char_to_idx.keys():\n",
        "                out.append(char_to_idx[w])\n",
        "            else:\n",
        "                out.append(len(char_to_idx.keys()))\n",
        "    else:\n",
        "        if word in char_to_idx.keys():\n",
        "            out.append(char_to_idx[word])\n",
        "        else:\n",
        "            out.append(len(char_to_idx.keys()))\n",
        "    out = np.array(out)\n",
        "    out = out[:,np.newaxis]\n",
        "    return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4fV7byCzVSt"
      },
      "source": [
        "def idx_to_char(idx):\n",
        "    if idx < len(embedding.keys()):\n",
        "        return list(embedding.keys())[idx]\n",
        "    else:\n",
        "        return '<unk>'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY6tlhfVldBD"
      },
      "source": [
        "def listToString(s): \n",
        "    \n",
        "    # initialize an empty string\n",
        "    str1 = \" \" \n",
        "    \n",
        "    # return string  \n",
        "    return (str1.join(s))\n",
        "\n",
        "def text_from_indices(seq):\n",
        "    output=[]\n",
        "    \n",
        "    for i in seq:\n",
        "        if i< len(embedding.keys()):\n",
        "            output.append(list(embedding.keys())[int(i)])\n",
        "        else:\n",
        "            output.append('<unk>')\n",
        "    return listToString(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FGm6uzQ0U3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e8c905ed-159d-4b01-f798-a5009923f4b0"
      },
      "source": [
        "idx_to_char(9417)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'satisfy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mmeCkyV8xUk"
      },
      "source": [
        "def split_inp_seq(seq):\n",
        "    return seq[:-1],seq[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTNOmD8rqbZA"
      },
      "source": [
        "from tensorflow.keras.layers import Dense,LSTM,Embedding, Input,Dropout, Activation,Reshape,GRU\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "Vocab_size = np.array(list(embedding.keys())).shape[0] + 1\n",
        "gru = tf.keras.layers.GRU(1512,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "\n",
        "\n",
        "densor = Dense(Vocab_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uGv9ZHtsMwz"
      },
      "source": [
        "def make_dataset(X,char_to_idx,embedding,max_len):\n",
        "    m = X.shape[0]                                   # number of training examples\n",
        "    \n",
        "    \n",
        "    # Initialize X_indices as a numpy matrix of zeros and the correct shape (â‰ˆ 1 line)\n",
        "    X_indices = []\n",
        "    \n",
        "    for i in range(m):                               # loop over training examples\n",
        "        \n",
        "        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n",
        "        sentence_words= X[i].split()\n",
        "        \n",
        "   \n",
        "        # Loop over the words of sentence_words\n",
        "\n",
        "        for w in sentence_words:\n",
        "            # if w exists in the word_to_index dictionary\n",
        "            if w in embedding.keys():\n",
        "                X_indices.append(char_to_idx[w])\n",
        "            \n",
        "    # X_indices = [i for i in X_indices.ravel() if i!=0]\n",
        "    \n",
        "    return X_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JL_lLEEtK1Z"
      },
      "source": [
        "X = make_dataset(np.array(dataset_orig),char_to_idx,embedding,largest_recipe)\n",
        "# np.array(padded_dataset.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMyaUu7y7INo",
        "outputId": "0521f552-cb80-45e7-99be-bc9f7781b8af"
      },
      "source": [
        "X =tf.Variable(X)\n",
        "X = tf.convert_to_tensor(X)\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6731,), dtype=int32, numpy=array([ 15703,   5240, 218643, ...,  32435,   5810,  21288], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSMq0qji8DJs"
      },
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3u6X2Xk68DMy"
      },
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gM0vUnLV61Pn",
        "outputId": "c6ead926-d98d-403b-e05d-601c5fb65cd5"
      },
      "source": [
        "len(embedding.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "291186"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTVMDyFn8DP1",
        "outputId": "9ea13fb3-365c-4874-c929-e5cbf017e4c8"
      },
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "    print(text_from_indices(seq))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "boil chicken and cool remove meat set aside in a large bowl add cream of chicken soups 1 1/2 cans of broth and 1 1/2 cans of milk stir altogether and add stuffing and chicken mix well together put 13 9 2-inch and round pan bake 35 40 minutes pan use may put pats of butter top place chicken in large casserole dish mix soup and milk pour chicken sprinkle parsley bake 1 1/2 hours serves 4 6 enjoy in 13 9-inch pan combine soups sour cream broth onion mushrooms and spices arrange chicken top of sauce bake uncovered 1 hour\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibet7Hzk8DSv"
      },
      "source": [
        "dataset = sequences.map(split_inp_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2xnpFTq9CZ3",
        "outputId": "06411a02-92d9-4d98-80d5-ca476670e2f1"
      },
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((32, 100), (32, 100)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euc-Unize0xc"
      },
      "source": [
        "def make_emb_layer(embedding):\n",
        "    vocab_size = np.array(list(embedding.keys())).shape[0] + 1   \n",
        "    embedding_dim = np.array(embedding[list(embedding.keys())[0]]).shape[0]\n",
        "\n",
        "    emb_matrix = np.zeros((vocab_size,embedding_dim))\n",
        "\n",
        "    for idx,word in enumerate(list(embedding.keys())):\n",
        "        emb_matrix[idx,:] = embedding[word]\n",
        "\n",
        "    embedding_layer = Embedding(vocab_size,output_dim=embedding_dim,trainable=False)\n",
        "    embedding_layer.build((None,))\n",
        "    embedding_layer.set_weights([emb_matrix])\n",
        "    return embedding_layer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSCKV4TliJ-8"
      },
      "source": [
        "class InitialEasyModel(tf.keras.Model):\n",
        "    def __init__(self,emb_layer,gru,densor):\n",
        "        super().__init__(self)\n",
        "        self.emb_layer = emb_layer\n",
        "        self.gru = gru\n",
        "        self.densor = densor\n",
        "        self.drop = Dropout(0.4)\n",
        "\n",
        "    def call(self, inputs, states=None, return_state=False, training=False):\n",
        "        x = inputs\n",
        "        x = self.emb_layer(x,training=training)\n",
        "\n",
        "        if states is None:\n",
        "            states = self.gru.get_initial_state(x)\n",
        "        x, states = self.gru(x, initial_state=states, training=training)\n",
        "   \n",
        "        x = self.drop(x)\n",
        "        x = self.densor(x, training=training)\n",
        "       \n",
        "        \n",
        "        if return_state:\n",
        "            return x, states\n",
        "        else:\n",
        "            return x\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-09pvJzkIf7"
      },
      "source": [
        "emb_layer = make_emb_layer(embedding)\n",
        "model = InitialEasyModel(emb_layer,gru,densor)\n",
        "input_shape =(16,100)\n",
        "model.build(input_shape=input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJSPqQZ_4xwf"
      },
      "source": [
        "opt = Adam()\n",
        "Loss =tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "EPOCHS = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WawBTCEytMa"
      },
      "source": [
        "model.compile(optimizer=opt,loss=Loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wikGwhpJnZey",
        "outputId": "5ced9b71-1c4b-419d-ac7c-7e2ca969e906"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"initial_easy_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  87356100  \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    multiple                  8228304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  440565931 \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "=================================================================\n",
            "Total params: 536,150,335\n",
            "Trainable params: 448,794,235\n",
            "Non-trainable params: 87,356,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEJKNXUjIMFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b81d5979-f602-437b-8ef8-87ba80718f50"
      },
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPKs2IFBIQa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32e925df-f2bd-4ebd-910c-d7cf88cf06ca"
      },
      "source": [
        "history.params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epochs': 20, 'steps': 2, 'verbose': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SXsuLZLR7mo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e67ef0b-86e2-423e-ebad-093964a63ae9"
      },
      "source": [
        "history.history.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-2vPjvgSTov",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "699e60e4-729e-41d9-d807-9ba3b3cea637"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqEiwOvBXM7n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ca30cc-ca49-440d-fb52-e717c34da039"
      },
      "source": [
        "chicken = np.array([120,560])\n",
        "chicken = chicken[:,np.newaxis]\n",
        "chicken"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[120],\n",
              "       [560]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGkyQrCAdD0E"
      },
      "source": [
        "class oneWord(tf.keras.Model):\n",
        "    def __init__(self,word_to_vec,text_from_id,model,vocab = 291187):\n",
        "        super().__init__(self)\n",
        "      \n",
        "        self.vec = word_to_vec\n",
        "        self.text = text_from_id\n",
        "        self.model = model\n",
        "\n",
        "        skip_id = self.vec('<unk>')\n",
        "        sparse_mask = tf.SparseTensor(\n",
        "       \n",
        "        values=[-float('inf')]*len(skip_id),\n",
        "        indices=skip_id,\n",
        "       \n",
        "        dense_shape=[vocab])\n",
        "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "    # @tf.function \n",
        "    def generate(self,inpword,states=None):\n",
        "        input = self.vec(inpword)\n",
        "\n",
        "        pred,states=self.model(input,states=states,return_state=True,training=False)\n",
        "        \n",
        "        pred = pred[:,-1,:]\n",
        "        pred = pred + self.prediction_mask\n",
        "        \n",
        "        pred = tf.random.categorical(pred,num_samples=1)\n",
        "\n",
        "        pred = tf.squeeze(pred,axis=-1)\n",
        "        pred = self.text(pred)\n",
        "        # print(pred)\n",
        "        return pred,states"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTN_naJgo4Wx"
      },
      "source": [
        "generator = oneWord(word_to_id,text_from_indices,model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqFGZG__2VZ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "e990c0ef-2436-4ae8-8d7e-bc44498ef502"
      },
      "source": [
        "next_w= 'put'\n",
        "out = [next_w]\n",
        "state=None\n",
        "for i in range(50):\n",
        "    next_w,state = generator.generate(next_w,state)\n",
        "    out.append(next_w)\n",
        "listToString(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'put Pappus cheeses adding flour full shredded smooth apple salt dish 5 olive seasonings place and juice sliced combine mix lemon place sauce thicken stir heat saute 4 1 45 onion pieces oil 45 medium-low cook two simmer of simmer and chicken evenly inches in pull breast margarine method 1/2 salt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S15Opu2Tq_Td"
      },
      "source": [
        "del model\n",
        "del dataset\n",
        "del X\n",
        "del generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DrYZP0u-l9z"
      },
      "source": [
        "def make_pad_dataset(max_inp,X,word_to_idx):\n",
        "    m = X.shape[0]\n",
        "    X_indices = np.full((m,max_inp),fill_value=len(word_to_idx) ,dtype=np.int)\n",
        "    for i in range(m):\n",
        "        sentence = X[i].split()\n",
        "        j = 0\n",
        "        for w in sentence:\n",
        "            if j < max_inp:\n",
        "                X_indices[i,j] = int(word_to_idx[w]) if w in word_to_idx.keys() else len(word_to_idx)\n",
        "                j+=1\n",
        "    return X_indices\n",
        "X = make_pad_dataset(420,np.array(dataset_orig),char_to_idx)+ 1e-5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMsgd9krmZYf",
        "outputId": "b836085e-2d54-4d93-a32d-0b897843fe0c"
      },
      "source": [
        "y = X.copy()\n",
        "y = np.roll(y,-1,1)\n",
        "y[0][1],X[0][2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(218643.00001, 218643.00001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 582
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQPpA0xNYc-H"
      },
      "source": [
        "\n",
        "X = tf.constant(X)\n",
        "X = tf.convert_to_tensor(X)\n",
        "y= tf.constant(y)\n",
        "y=tf.convert_to_tensor(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvzyFznjYkZe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e7aeccc-2810-4e17-c655-6d89a2d71d64"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((X,y))\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((420,), (420,)), types: (tf.float64, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 531
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIIsnVhcgpon"
      },
      "source": [
        "# dataset = dataset.map(split_inp_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS1T5wQjZ7Kz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6393a58c-b9f9-45d6-fd94-cf8a7efe1744"
      },
      "source": [
        "BATCH_SIZE = 4\n",
        "\n",
        "BUFFER_SIZE = 1000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((4, 420), (4, 420)), types: (tf.float64, tf.float64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxTLRcXYaZo5"
      },
      "source": [
        "class ModelWithPadding(tf.keras.Model):\n",
        "    def __init__(self, num_gru,vocab_size,emb_layer):\n",
        "        super().__init__(self)\n",
        "        self.gru = GRU(num_gru,return_sequences=True,return_state=True)\n",
        "        self.emb = emb_layer\n",
        "        self.dense = Dense(vocab_size)\n",
        "        self.drop = Dropout(0.4)\n",
        "\n",
        "    def call(self,input,states=None,return_state=False,training=False):\n",
        "        X = input\n",
        "        X  = self.emb(X)\n",
        "        if states is None:\n",
        "            states = self.gru.get_initial_state(X)\n",
        "        X,states = self.gru(X,training=training,initial_state=states)\n",
        "        x = self.drop(X)\n",
        "        x = self.dense(x)\n",
        "\n",
        "        if return_state:\n",
        "            return x,states\n",
        "        else:\n",
        "            return x\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPSXD8KwccXb"
      },
      "source": [
        "model_with_padding = ModelWithPadding(516,Vocab_size,emb_layer)\n",
        "input_shape = (4,420)\n",
        "model_with_padding.build(input_shape= input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0bfL1h4eIuK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9eb5529-2f3a-4392-ee8e-4ac72df1ddb7"
      },
      "source": [
        "model_with_padding.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_with_padding_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_17 (GRU)                 multiple                  1266264   \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        multiple                  87356100  \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             multiple                  150543679 \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         multiple                  0         \n",
            "=================================================================\n",
            "Total params: 239,166,043\n",
            "Trainable params: 151,809,943\n",
            "Non-trainable params: 87,356,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLtA6LgJedWj"
      },
      "source": [
        "opt = Adam(clipvalue=0.5)\n",
        "Loss =tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "EPOCHS = 15\n",
        "model_with_padding.compile(optimizer=opt,loss=Loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkmXKS5deNmu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3da89b6-1ba7-419a-c821-fcc99586359e"
      },
      "source": [
        "history = model_with_padding.fit(dataset,epochs=EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "37/37 [==============================] - 25s 648ms/step - loss: 5.0429\n",
            "Epoch 2/15\n",
            "37/37 [==============================] - 25s 671ms/step - loss: 1.0217\n",
            "Epoch 3/15\n",
            "37/37 [==============================] - 25s 685ms/step - loss: 0.9235\n",
            "Epoch 4/15\n",
            "37/37 [==============================] - 26s 690ms/step - loss: 0.8253\n",
            "Epoch 5/15\n",
            "37/37 [==============================] - 26s 703ms/step - loss: 0.7683\n",
            "Epoch 6/15\n",
            "37/37 [==============================] - 27s 717ms/step - loss: 0.7488\n",
            "Epoch 7/15\n",
            "37/37 [==============================] - 27s 733ms/step - loss: 0.7158\n",
            "Epoch 8/15\n",
            "37/37 [==============================] - 27s 743ms/step - loss: 0.7129\n",
            "Epoch 9/15\n",
            "37/37 [==============================] - 27s 741ms/step - loss: 0.7043\n",
            "Epoch 10/15\n",
            "37/37 [==============================] - 27s 732ms/step - loss: 0.6967\n",
            "Epoch 11/15\n",
            "37/37 [==============================] - 28s 747ms/step - loss: 0.6908\n",
            "Epoch 12/15\n",
            "37/37 [==============================] - 27s 741ms/step - loss: 0.6937\n",
            "Epoch 13/15\n",
            "37/37 [==============================] - 27s 734ms/step - loss: 0.6849\n",
            "Epoch 14/15\n",
            "37/37 [==============================] - 27s 739ms/step - loss: 0.6732\n",
            "Epoch 15/15\n",
            "37/37 [==============================] - 27s 742ms/step - loss: 0.6774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDnGQuG5Gd-x"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVuV9kEn0L3w"
      },
      "source": [
        "generator = oneWord(word_to_id,text_from_indices,model_with_padding)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "IHJY97j7M_xe",
        "outputId": "c5a1b645-24e2-4be0-b61f-4efa624bfe52"
      },
      "source": [
        "w = 'boil'\n",
        "state = None\n",
        "out =[w]\n",
        "for i in range(120):\n",
        "    w,state = generator.generate(w,states=state)\n",
        "    out.append(w)\n",
        "listToString(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'boil place chili cutlets chicken cover resealable minutes the skillet uncovered milk turn cornflakes and in and the pan in pieces skillet the milk add large add simmer beginning brown heat the saute tomatoes add chicken and crust pour brown corn half hollandaise golden bread sauce the coconut and add nacho 1 in cook onion avocado chicken garlic method beef chicken sprigs sauce and large brushing bacon stirring pan add gently of powder pan stir curry simmer side coconut plate stir medium-high bubbles and powder serve in pan of salt sauce in juice baking broth stir the heat 1 curry dabs together 1 water a chips golden chicken pan turn chicken and pieces and pieces smooth wing bring and and brown'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unk3S3QfhCOn"
      },
      "source": [
        "dataset = [i.lower().replace('.','') for i in text.split()]\n",
        "vocab =list(set(dataset))\n",
        "vocab.append('<unk>')\n",
        "# vocab\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6whqcuKhXQV"
      },
      "source": [
        "char_to_id ={}\n",
        "for i,word in enumerate(vocab):\n",
        "    char_to_id[word] = float(i)\n",
        "char_to_id['chicken']\n",
        "\n",
        "def word_to_vec(word):\n",
        "    out =[]\n",
        "    if type(word) == type([]):\n",
        "        word = np.array(word).reshape(-1)\n",
        "        for w in word:\n",
        "            if w in char_to_id.keys():\n",
        "                out.append(char_to_id[w])\n",
        "            else:\n",
        "                out.append(len(char_to_id.keys()))\n",
        "    else:\n",
        "        if word in char_to_id.keys():\n",
        "            out.append(char_to_id[word])\n",
        "        else:\n",
        "            out.append(len(char_to_id.keys()))\n",
        "    out = np.array(out)\n",
        "    out = out[:,np.newaxis]\n",
        "    return out\n",
        "\n",
        "def text_from_id(seq):\n",
        "    output=[]\n",
        "    \n",
        "    for i in seq:\n",
        "        if i< len(char_to_id.keys()):\n",
        "            output.append(list(char_to_id.keys())[int(i)])\n",
        "        else:\n",
        "            output.append('<unk>')\n",
        "    return listToString(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9B83xA1oETJ"
      },
      "source": [
        "def ids_to_char(ids):\n",
        "    out = []\n",
        "    for i in ids:\n",
        "        out.append(vocab[i]) if i < len(vocab) else out.append('<unk>')\n",
        "\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dk563ruzlcy8"
      },
      "source": [
        "def make_emb_data(max_inp,word_to_idx,X):\n",
        "    m = X.shape[0]\n",
        "    X_indices = np.full((m,max_inp),fill_value=len(word_to_idx))\n",
        "    for i in range(m):\n",
        "        sentence = X[i].split()\n",
        "        j = 0\n",
        "        for w in sentence:\n",
        "            if j < max_inp:\n",
        "                X_indices[i,j] = int(word_to_idx[w]) if w in word_to_idx.keys() else len(word_to_idx)\n",
        "                j+=1\n",
        "    return X_indices\n",
        "\n",
        "X = make_emb_data(largest_recipe,char_to_id,np.array(dataset_orig))\n",
        "y = X.copy()\n",
        "y = np.roll(y,-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xalHU6jDts47",
        "outputId": "a5c84df6-5e11-4d01-8dda-b3bbae085ca0"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 730)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 716
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1V3EImOlce5",
        "outputId": "43c1e956-b2fa-4ba5-d93a-ef641b457082"
      },
      "source": [
        "X = tf.constant(X)\n",
        "X = tf.convert_to_tensor(X)\n",
        "y= tf.constant(y)\n",
        "y=tf.convert_to_tensor(y)\n",
        "y,X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(150, 730), dtype=int64, numpy=\n",
              " array([[1192,   22,  193, ..., 1212, 1212,  759],\n",
              "        [1192,  139, 1193, ..., 1212, 1212,  571],\n",
              "        [ 931,  761, 1162, ..., 1212, 1212,  139],\n",
              "        ...,\n",
              "        [ 754, 1192,    1, ..., 1212, 1212, 1067],\n",
              "        [1120,   22, 1140, ..., 1212, 1212,  297],\n",
              "        [1120, 1140,   22, ..., 1212, 1212,  297]])>,\n",
              " <tf.Tensor: shape=(150, 730), dtype=int64, numpy=\n",
              " array([[ 759, 1192,   22, ..., 1212, 1212, 1212],\n",
              "        [ 571, 1192,  139, ..., 1212, 1212, 1212],\n",
              "        [ 139,  931,  761, ..., 1212, 1212, 1212],\n",
              "        ...,\n",
              "        [1067,  754, 1192, ..., 1212, 1212, 1212],\n",
              "        [ 297, 1120,   22, ..., 1212, 1212, 1212],\n",
              "        [ 297, 1120, 1140, ..., 1212, 1212, 1212]])>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 717
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4giQdfHozTza"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((X,y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3lS5piitmGN",
        "outputId": "7dd386f1-5b4f-410f-fe88-2fd9bf8186e3"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((32, 730), (32, 730)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 719
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tflbU3Hg72V"
      },
      "source": [
        "class CustomEmbedding(tf.keras.Model):\n",
        "    def __init__(self, num_gru,vocab_size):\n",
        "        super().__init__(self)\n",
        "        self.gru = GRU(num_gru,return_sequences=True,return_state=True)\n",
        "        self.emb = Embedding(vocab_size,output_dim=1024)\n",
        "        self.dense = Dense(vocab_size)\n",
        "        self.drop = Dropout(0.4)\n",
        "\n",
        "    def call(self,input,states=None,return_state=False,training=False):\n",
        "        X = input\n",
        "        X  = self.emb(X,training=training)\n",
        "        if states is None:\n",
        "            states = self.gru.get_initial_state(X)\n",
        "        x,states = self.gru(X,training=training,initial_state=states)\n",
        "      \n",
        "        x = self.drop(X)\n",
        "        x = self.dense(x)\n",
        "\n",
        "        if return_state:\n",
        "            return x,states\n",
        "        else:\n",
        "            return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU-J7CQhug_-"
      },
      "source": [
        "custom_embedding = CustomEmbedding(4024,1213)\n",
        "input_shape =(32,730)\n",
        "custom_embedding.build(input_shape=input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0fosvRJu6h5",
        "outputId": "86d0576d-09b2-409e-eb9c-20053e62f98d"
      },
      "source": [
        "custom_embedding.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"custom_embedding_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_26 (GRU)                 multiple                  60963600  \n",
            "_________________________________________________________________\n",
            "embedding_25 (Embedding)     multiple                  1242112   \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             multiple                  1243325   \n",
            "_________________________________________________________________\n",
            "dropout_42 (Dropout)         multiple                  0         \n",
            "=================================================================\n",
            "Total params: 63,449,037\n",
            "Trainable params: 63,449,037\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2TLnWO2u9yh"
      },
      "source": [
        "custom_embedding.compile(loss=Loss,optimizer=opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_9z9B5vvrh6",
        "outputId": "58a8a399-1720-4494-838c-f496464f2fca"
      },
      "source": [
        "history = custom_embedding.fit(X,y,32,100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['gru_26/gru_cell_26/kernel:0', 'gru_26/gru_cell_26/recurrent_kernel:0', 'gru_26/gru_cell_26/bias:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['gru_26/gru_cell_26/kernel:0', 'gru_26/gru_cell_26/recurrent_kernel:0', 'gru_26/gru_cell_26/bias:0'] when minimizing the loss.\n",
            "5/5 [==============================] - 1s 107ms/step - loss: 6.6840\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 4.4456\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 1.1201\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.5009\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.4606\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.4254\n",
            "Epoch 7/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.3963\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.3732\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.3534\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.3376\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.3243\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.3125\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.3020\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.2926\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.2846\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.2777\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.2709\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2651\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.2600\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2562\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2510\n",
            "Epoch 22/100\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.2476\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2443\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2414\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 0s 90ms/step - loss: 0.2388\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2364\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.2343\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2323\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2307\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.2290\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2277\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.2268\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2262\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.2250\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2241\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.2237\n",
            "Epoch 37/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2230\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.2229\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.2220\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.2216\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2211\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2211\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2212\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2202\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.2202\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.2194\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2194\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.2193\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2189\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2190\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2185\n",
            "Epoch 52/100\n",
            "5/5 [==============================] - 0s 93ms/step - loss: 0.2186\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 0s 92ms/step - loss: 0.2182\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2182\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2182\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.2182\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2177\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2174\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2170\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2172\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.2175\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2172\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.2175\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.2167\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2172\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2162\n",
            "Epoch 67/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2163\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2162\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 0s 99ms/step - loss: 0.2161\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.2157\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2162\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.2157\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.2160\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.2157\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2153\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 0s 100ms/step - loss: 0.2153\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 1s 99ms/step - loss: 0.2161\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2154\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 0s 98ms/step - loss: 0.2153\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2155\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 1s 101ms/step - loss: 0.2156\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2150\n",
            "Epoch 83/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2149\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 0s 97ms/step - loss: 0.2154\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2148\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2147\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2146\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2154\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2148\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2145\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2147\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2144\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 0s 94ms/step - loss: 0.2147\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 0s 96ms/step - loss: 0.2140\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2146\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2146\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.2141\n",
            "Epoch 98/100\n",
            "5/5 [==============================] - 1s 106ms/step - loss: 0.2141\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2144\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 0s 95ms/step - loss: 0.2146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49fs8HzCGf5W"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3trbJxg5vxmi"
      },
      "source": [
        "generator = oneWord(word_to_vec,text_from_id,custom_embedding,vocab=len(char_to_id.keys())+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "xxTXoYZC3vFB",
        "outputId": "ff16e49f-61d0-47cd-e11e-86183b7e542f"
      },
      "source": [
        "w = 'boil'\n",
        "state = None\n",
        "out =[w]\n",
        "for i in range(50):\n",
        "    w,state = generator.generate(w,states=state)\n",
        "    out.append(w)\n",
        "listToString(out).replace('<unk>' , ' ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'boil then cover and water over medium-low heat cast-iron skillet and carrots bay leaf divide the curry powder salt for required pieces and sausage * (if using) and sour cream slowly over moderate heat about 1 more seasonings dredge in large stockpot heat to simmer for about 1 hour very light'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 737
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxgwKtfh_INt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}